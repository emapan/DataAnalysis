{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import copy  \n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import SMOTE  \n",
    "from sklearn.ensemble import AdaBoostClassifier,VotingClassifier,GradientBoostingClassifier,RandomForestClassifier,BaggingClassifier  \n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score  \n",
    "from sklearn.preprocessing import LabelEncoder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据审查和预处理函数\n",
    "\n",
    "\n",
    "# 基本状态查看\n",
    "def stats_summary(df):\n",
    "    '''\n",
    "    查看数据集的记录数、维度数、前2条数据、描述性统计和数据类型\n",
    "    :param df: 数据框\n",
    "    :return: 无\n",
    "    '''\n",
    "    print('Data Overview:')\n",
    "    print('Records: {0}\\tDimension：{1}'.format(df.shape[0], df.shape[1]))  # 打印数据形状\n",
    "    print('-' * 30)\n",
    "    print('The first two rows:')\n",
    "    print(df.head(2))    # 输出前2条数据\n",
    "    print('-' * 30)\n",
    "    print('Data Desc:')\n",
    "    print(df.describe())  # 输出数据描述性统计信息\n",
    "    print('-' * 30)\n",
    "    print('Data Dtypes:')\n",
    "    print(df.dtypes)      # 输出数据类型\n",
    "    print('-' * 60)\n",
    "\n",
    "    \n",
    "# 缺失值查看\n",
    "def na_summary(df):\n",
    "    '''\n",
    "    查看数据集的缺失列、行数量\n",
    "    :param df: 数据框\n",
    "    :return: 无\n",
    "    '''\n",
    "    na_cols = df.isnull().any(axis=0)    # 判断每一列是否具有缺失值\n",
    "    print('NA Cols:')\n",
    "    print(na_cols)  \n",
    "    print('-' * 30)\n",
    "    print('Valid records for each cols:') # 查看每一列有效值（非NA）的记录数\n",
    "    print(df.count())                  \n",
    "    print('-' * 30)\n",
    "    print('Total number of NA lines is: {0}'.format(df.isnull().any(axis=1).sum()))  # 查看具有缺失值的行的记录数\n",
    "    print('-' * 60)\n",
    "\n",
    "\n",
    "# 字符串分类转数值分类\n",
    "def label_encoder(data, model_list=None, train=True):\n",
    "    '''\n",
    "    将特征中的字符串分类转换为数值分类\n",
    "    :param data: 输入数据集\n",
    "    :param model_list: LabelEncoder对象列表，在训练阶段产生\n",
    "    :param train: 是否为训练阶段\n",
    "    :return: 训练阶段产生训练后的LabelEncoder对象列表和转换后的数据，预测阶段产生转换后的数据\n",
    "    '''\n",
    "    convert_cols = ['cat', 'attribution', 'pro_id', 'pro_brand', 'order_source', 'pay_type','use_id', 'city']  # 定义要转换的列\n",
    "    value_list = []  # 存放转换后的数据\n",
    "    if train:\n",
    "        model_list = []  # 存放每个特征转换的实例对象\n",
    "        model_label_encoder = LabelEncoder()\n",
    "        for i in convert_cols:\n",
    "            model_label_encoder.fit(data[i])\n",
    "            value_list.append(model_label_encoder.transform(data[i]))\n",
    "            model_list.append(copy.copy(model_label_encoder))\n",
    "            # print(list(model_label_encoder.classes_))\n",
    "        convert_matrix = np.array(value_list).T\n",
    "        return model_list, convert_matrix\n",
    "    else:\n",
    "        for ind, j in enumerate(convert_cols):\n",
    "            # print(list(model_list[ind].classes_))\n",
    "            value_list.append(model_list[ind].transform(data[j]))\n",
    "        convert_matrix = np.array(value_list).T\n",
    "        return convert_matrix\n",
    "\n",
    "\n",
    "# 时间属性拓展\n",
    "def datetime2int(date_series,time_series):\n",
    "    '''\n",
    "    将日期和时间数据拓展出其他属性，例如星期几、周几、小时、分钟等。\n",
    "    :param date_series: 日期列\n",
    "    :param time_series: 时间列\n",
    "    :return: 拓展后的属性矩阵\n",
    "    '''\n",
    "    date_set = [datetime.strptime(dates, '%Y-%m-%d') for dates in date_series]  # 将data_series转换为特定日期格式\n",
    "    weekday_data = [data.weekday() for data in date_set]  # 周几\n",
    "    day_data = [data.day for data in date_set]            # 当月几号\n",
    "    month_data = [data.month for data in date_set]        # 月份\n",
    "\n",
    "    time_set = [datetime.strptime(times, '%H:%M:%S') for times in time_series]  # 将time_series转换为特定时间格式\n",
    "    second_data = [data.second for data in time_set]  # 秒\n",
    "    minute_data = [data.minute for data in time_set]  # 分钟\n",
    "    hour_data = [data.hour for data in time_set]      # 小时\n",
    "\n",
    "    final_set = [weekday_data, day_data, month_data, second_data, minute_data, hour_data]  # 将属性列表批量组合\n",
    "    final_matrix = np.array(final_set).T  # 转换为矩阵并转置\n",
    "    return final_matrix\n",
    "\n",
    "\n",
    "# 样本均衡审查\n",
    "def label_summary(df,labels,samples):\n",
    "    '''\n",
    "    查看每个类的样本量分布\n",
    "    :param df: 数据框\n",
    "    :param labels: 类别列名\n",
    "    :param samples: 其他有效列名(无NA值)\n",
    "    :return: 无\n",
    "    '''\n",
    "    print('Labels samples distribution:')\n",
    "    print(df[samples].groupby(df[labels]).count())  \n",
    "    print('-' * 60)\n",
    "\n",
    "\n",
    "# 样本均衡\n",
    "def sample_balance(X, y):\n",
    "    '''\n",
    "    使用SMOTE方法对不均衡样本做过抽样处理\n",
    "    :param X: 输入特征变量X\n",
    "    :param y: 目标变量y\n",
    "    :return: 均衡后的X和y\n",
    "    '''\n",
    "    model_smote = SMOTE()  # 建立SMOTE模型对象\n",
    "    x_smote_resampled, y_smote_resampled = model_smote.fit_resample(X, y)  # 输入数据并作过抽样处理\n",
    "    return x_smote_resampled, y_smote_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Overview:\n",
      "Records: 134190\tDimension：14\n",
      "------------------------------\n",
      "The first two rows:\n",
      "     order_id  order_date order_time     cat attribution      pro_id  \\\n",
      "0  4277880103  2013-10-17   13:09:16     NaN          GO  8000001215   \n",
      "1  4283851335  2013-09-23   14:09:49  手机摄影数码         POP  8002042497   \n",
      "\n",
      "  pro_brand  total_money  total_quantity order_source pay_type      use_id  \\\n",
      "0       NaN       1000.0            1000         游戏站点     当当支付  murongchun   \n",
      "1        三星     766000.0             200           主站     合并支付   dakehu_zy   \n",
      "\n",
      "  city  abnormal_label  \n",
      "0  北京市               0  \n",
      "1  上海市               1  \n",
      "------------------------------\n",
      "Data Desc:\n",
      "         total_money  total_quantity  abnormal_label\n",
      "count  134189.000000   134190.000000   134190.000000\n",
      "mean      660.111987        1.195588        0.212065\n",
      "std      2901.208639        3.230545        0.408772\n",
      "min         0.500000        1.000000        0.000000\n",
      "25%        29.000000        1.000000        0.000000\n",
      "50%        98.400000        1.000000        0.000000\n",
      "75%       372.000000        1.000000        0.000000\n",
      "max    766000.000000     1000.000000        1.000000\n",
      "------------------------------\n",
      "Data Dtypes:\n",
      "order_id           object\n",
      "order_date         object\n",
      "order_time         object\n",
      "cat                object\n",
      "attribution        object\n",
      "pro_id             object\n",
      "pro_brand          object\n",
      "total_money       float64\n",
      "total_quantity      int64\n",
      "order_source       object\n",
      "pay_type           object\n",
      "use_id             object\n",
      "city               object\n",
      "abnormal_label      int64\n",
      "dtype: object\n",
      "------------------------------------------------------------\n",
      "NA Cols:\n",
      "order_id          False\n",
      "order_date        False\n",
      "order_time        False\n",
      "cat                True\n",
      "attribution       False\n",
      "pro_id            False\n",
      "pro_brand          True\n",
      "total_money        True\n",
      "total_quantity    False\n",
      "order_source      False\n",
      "pay_type          False\n",
      "use_id            False\n",
      "city               True\n",
      "abnormal_label    False\n",
      "dtype: bool\n",
      "------------------------------\n",
      "Valid records for each cols:\n",
      "order_id          134190\n",
      "order_date        134190\n",
      "order_time        134190\n",
      "cat               132800\n",
      "attribution       134190\n",
      "pro_id            134190\n",
      "pro_brand         133418\n",
      "total_money       134189\n",
      "total_quantity    134190\n",
      "order_source      134190\n",
      "pay_type          134190\n",
      "use_id            134190\n",
      "city              134188\n",
      "abnormal_label    134190\n",
      "dtype: int64\n",
      "------------------------------\n",
      "Total number of NA lines is: 1429\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 读取数据集\n",
    "# 定义特殊字段数据格式\n",
    "dtypes = {'order_id': object,\n",
    "          'pro_id': object,\n",
    "          'use_id': object}\n",
    "raw_data = pd.read_table('abnormal_orders.txt', delimiter=',', dtype=dtypes)  \n",
    "\n",
    "# 数据审查\n",
    "stats_summary(raw_data)  # 基本状态查看\n",
    "na_summary(raw_data)  # 缺失值审查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels samples distribution:\n",
      "abnormal_label\n",
      "0    105733\n",
      "1     28457\n",
      "Name: use_id, dtype: int64\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "label_summary(raw_data,'abnormal_label','use_id')  # 类样本分布审查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "drop_na_set = raw_data.dropna()  # 丢弃带有NA值的数据行\n",
    "X_raw, y_raw = drop_na_set.iloc[:, 1:-1], drop_na_set.iloc[:, -1]  # 分割输入变量X和y\n",
    "model_list, convert_matrix = label_encoder(X_raw)  # 字符串分类转整数型分类\n",
    "datetime2int_data = datetime2int(X_raw['order_date'],X_raw['order_time'])  # 拓展日期时间属性\n",
    "combine_set = np.hstack((convert_matrix, datetime2int_data))  # 合并转换后的分类和拓展后的日期数据集\n",
    "constant_set = X_raw[['total_money', 'total_quantity']]  # 原始连续数据变量\n",
    "X_combine = np.hstack((combine_set, constant_set))  # 再次合并数据集\n",
    "X, y = sample_balance(X_combine, y_raw)  # 样本均衡处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val scores:[0.42571367 0.85707449 0.91730277 0.8800938  0.80416368]\n",
      "Mean scores is: 0.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('randomforest',\n",
       "                              RandomForestClassifier(max_features=0.8,\n",
       "                                                     random_state=0)),\n",
       "                             ('adaboost', AdaBoostClassifier(random_state=0)),\n",
       "                             ('bagging', BaggingClassifier(random_state=0)),\n",
       "                             ('gradientboosting',\n",
       "                              GradientBoostingClassifier(max_features=0.8,\n",
       "                                                         random_state=0))],\n",
       "                 n_jobs=-1, voting='soft', weights=[0.9, 1.2, 1.1, 1.1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 组合分类模型交叉检验\n",
    "model_rf = RandomForestClassifier(max_features=0.8, random_state=0)  # 随机森林分类模型对象\n",
    "model_adaC = AdaBoostClassifier(random_state=0)  # Adaboost分类模型对象\n",
    "model_BagC = BaggingClassifier(random_state=0)  # Bagging分类模型对象\n",
    "model_gdbc = GradientBoostingClassifier(max_features=0.8, random_state=0)  # GradientBoosting分类模型对象\n",
    "estimators = [('randomforest', model_rf), ('adaboost', model_adaC),\n",
    "              ('bagging', model_BagC), ('gradientboosting', model_gdbc)]  # 建立组合评估器列表\n",
    "model_vot = VotingClassifier(estimators=estimators, voting='soft', weights=[0.9, 1.2, 1.1, 1.1],n_jobs=-1)  # 建立组合评估模型\n",
    "cv = StratifiedKFold(5)  # 设置交叉检验方法\n",
    "cv_score = cross_val_score(model_vot, X, y, cv=cv)  # 交叉检验\n",
    "print('Cross val scores:{}'.format(cv_score))    # 打印每次交叉检验得分\n",
    "print('Mean scores is: %.2f' % cv_score.mean())  # 打印平均交叉检验得分\n",
    "model_vot.fit(X, y)  # 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels:[1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 新数据集做预测\n",
    "X_raw_data = pd.read_csv('new_abnormal_orders.csv', dtype=dtypes)  # 读取要预测的数据集\n",
    "X_raw_new = X_raw_data.iloc[:, 1:]  # 丢弃订单ID列\n",
    "convert_matrix_new = label_encoder(X_raw_new, model_list, False)  # 字符串分类转整数型分类\n",
    "datetime2int_data_new = datetime2int(X_raw_new['order_date'],X_raw_new['order_time'])  # 日期时间转换\n",
    "combine_set_new = np.hstack((convert_matrix_new, datetime2int_data_new))  # 合并转换后的分类和拓展后的日期数据集\n",
    "constant_set_new = X_raw_new[['total_money', 'total_quantity']]  # 原始连续数据变量\n",
    "X_combine_new = np.hstack((combine_set_new, constant_set_new))  # 再次合并数据集\n",
    "y_predict = model_vot.predict(X_combine_new)  # 预测结果\n",
    "print('Predicted labels:{}'.format(y_predict)) # 打印预测值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
